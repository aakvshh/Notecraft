{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5885,"status":"ok","timestamp":1707556381301,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"gN7fj7CMb-j1"},"outputs":[],"source":["import numpy as np\n","import librosa\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":13513,"status":"ok","timestamp":1707556394807,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"12pSsa1BcYa8"},"outputs":[],"source":["fixed_length = 44100\n","fft = librosa.feature.mfcc"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1707556394808,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"ZBmc94zudqkr"},"outputs":[],"source":["def parse_note_from_filename(filename):\n","    parts = filename.split('_')\n","\n","    if len(parts) > 0:\n","        return parts[0]\n","    else:\n","        return 'unknown'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1707556394809,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"VEh7nbZkcKG2"},"outputs":[],"source":["def preprocess_audio(audio_file_path, target_length=fixed_length):\n","    audio, sr = librosa.load(audio_file_path, sr=None)\n","\n","    # Ensure that all audio samples have the same length\n","    if len(audio) < target_length:\n","        audio = np.pad(audio, (0, target_length - len(audio)))\n","    elif len(audio) > target_length:\n","        audio = audio[:target_length]\n","\n","\n","    fft_result = np.fft.fft(audio)\n","    magnitudes = np.abs(fft_result)\n","\n","    return magnitudes"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":21245,"status":"ok","timestamp":1707556416040,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"mzBw-ZpbdaIc"},"outputs":[],"source":["audio_samples = []\n","musical_notes = []\n","folder_path = '/content/drive/MyDrive/BE Project/88-1sec-increased'\n","\n","for filename in os.listdir(folder_path):\n","    if filename.endswith('.wav'):\n","        file_path = os.path.join(folder_path, filename)\n","\n","        features = preprocess_audio(file_path)\n","\n","        note = parse_note_from_filename(filename)\n","\n","        audio_samples.append(features)\n","        musical_notes.append(note)\n","\n","X = np.array(audio_samples)\n","y = np.array(musical_notes)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":852,"status":"ok","timestamp":1707556416833,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"3uLAepNod4hU"},"outputs":[],"source":["# Split the data\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale the features using StandardScaler\n","scaler = StandardScaler()\n","\n","# Fit on training data and transform both training and test data\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test) "]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1707556815827,"user":{"displayName":"Siddhi Jagtap","userId":"07861269421910309248"},"user_tz":-330},"id":"Ci9F2aqPbhQl","outputId":"87afe2db-4124-4a1d-ddae-49045062bd8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Predicted Note (SVM): F#\n"]}],"source":["import joblib\n","svm_model = joblib.load('/content/drive/MyDrive/BE Project/Sem2/Review1/modelinc1sec.joblib')\n","\n","def predict_note_svm(audio_file_path, model, scaler):\n","    audio, _ = librosa.load(audio_file_path, sr=None)\n","    features = preprocess_audio(audio_file_path)\n","\n","    # Scale the features using the same scaler used during training\n","    features_scaled = scaler.transform(features.reshape(1, -1))\n","\n","    # Predict the note using the SVM model\n","    predicted_note = model.predict(features_scaled)[0]\n","\n","    return predicted_note\n","\n","# audio_file_path = '/content/drive/MyDrive/BE Project/88-piano_new/B_6.wav'\n","audio_file_path = '/content/drive/MyDrive/BE Project/dataset_test/c4.ogg'\n","predicted_note_svm = predict_note_svm(audio_file_path, svm_model, scaler)\n","print(f\"Predicted Note (SVM): {predicted_note_svm}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJU13gFxcrG6"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
