{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4fae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0df6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_note_from_filename(filename):\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    if len(parts) > 0:\n",
    "        return parts[0]\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f80980f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "# Set a fixed length for all audio samples (you can adjust this as needed)\n",
    "fixed_length = 44100  # for example, 1 second at 44.1 kHz\n",
    "\n",
    "audio_samples = []\n",
    "musical_notes = []\n",
    "\n",
    "# Define a function to load and preprocess an audio file\n",
    "def preprocess_audio(audio_file_path, target_length=fixed_length):\n",
    "    audio, sr = librosa.load(audio_file_path, sr=None)\n",
    "    \n",
    "    # Ensure that all audio samples have the same length\n",
    "    if len(audio) < target_length:\n",
    "        audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "    elif len(audio) > target_length:\n",
    "        audio = audio[:target_length]\n",
    "    \n",
    "    # Extract features (FFT in this case)\n",
    "    fft_result = np.fft.fft(audio)\n",
    "    magnitudes = np.abs(fft_result)\n",
    "    \n",
    "    return magnitudes\n",
    "\n",
    "folder_path = 'piano_triads'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.wav'):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Preprocess the audio and extract features\n",
    "        features = preprocess_audio(file_path)\n",
    "        \n",
    "        note = parse_note_from_filename(filename)\n",
    "        \n",
    "        audio_samples.append(features)\n",
    "        musical_notes.append(note)\n",
    "\n",
    "X = np.array(audio_samples)\n",
    "y = np.array(musical_notes)\n",
    "\n",
    "# Now, X contains the preprocessed audio features (FFT magnitudes) and y contains the corresponding musical notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a89e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_samples, sample_rate=44100):\n",
    "    features = []\n",
    "    for audio in audio_samples:\n",
    "        # Applying FFT\n",
    "        fft_result = np.fft.fft(audio)\n",
    "        magnitudes = np.abs(fft_result)\n",
    "        \n",
    "        features.append(magnitudes)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8a5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = extract_features(audio_samples)\n",
    "\n",
    "# mean_magnitudes = [np.mean(feature) for feature in features]\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(mean_magnitudes)\n",
    "# plt.xlabel('Sample Index')\n",
    "# plt.ylabel('Mean Magnitude')\n",
    "# plt.title('Mean Magnitude of FFT Coefficients for Audio Samples')\n",
    "# plt.grid()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43edfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# num_samples_to_visualize = 50\n",
    "\n",
    "# for i in range(num_samples_to_visualize):\n",
    "#     plt.figure(figsize=(7, 4))\n",
    "#     plt.specgram(X[i], Fs=sr, cmap='inferno')\n",
    "\n",
    "#     filename = os.listdir(folder_path)[i]\n",
    "    \n",
    "#     plt.title(f'Spectrogram of {filename}')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Frequency (Hz)')\n",
    "#     plt.colorbar(format='%+2.0f dB')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be14c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #amplitude vs frequency\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# num_samples_to_visualize = 50\n",
    "\n",
    "# for i in range(num_samples_to_visualize):\n",
    "#     plt.figure(figsize=(7, 4))\n",
    "    \n",
    "#     fft_result = np.fft.fft(X[i])\n",
    "    \n",
    "#     frequencies = np.fft.fftfreq(len(fft_result), 1/sr)\n",
    "#     amplitudes = np.abs(fft_result)\n",
    "\n",
    "#     plt.plot(frequencies[:len(frequencies)//2], amplitudes[:len(amplitudes)//2])  \n",
    "#     filename = os.listdir(folder_path)[i]\n",
    "    \n",
    "#     plt.title(f'Amplitude vs. Frequency of {filename}')\n",
    "#     plt.xlabel('Frequency (Hz)')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.grid()\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # waveform plot\n",
    "# import librosa.display\n",
    "\n",
    "# num_samples_to_visualize = 40\n",
    "\n",
    "# for i in range(num_samples_to_visualize):\n",
    "#     plt.figure(figsize=(7, 4))\n",
    "#     plt.plot(np.arange(len(X[i])) / sr, X[i])\n",
    "#     filename = os.listdir(folder_path)[i]\n",
    "\n",
    "#     plt.title(f'Waveform of Audio Sample {filename}')\n",
    "#     plt.xlabel('Time (s)')\n",
    "#     plt.ylabel('Amplitude')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab2c5e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64b1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# # Sample labels\n",
    "# y_train = [\"C\", \"Cs\", \"D\", \"Eb\", \"E\", \"F\", \"Fs\", \"G\", \"Gs\", \"A\", \"Bb\", \"B\"]\n",
    "\n",
    "# # Initialize the OneHotEncoder\n",
    "# one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# # Reshape and fit-transform the labels\n",
    "# y_train_encoded = one_hot_encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "\n",
    "# # Now, y_train_encoded contains the one-hot encoded labels\n",
    "\n",
    "# # Inverse transformation (decoding)\n",
    "# y_train_decoded = one_hot_encoder.inverse_transform(y_train_encoded)\n",
    "\n",
    "# y_test_encoded = one_hot_encoder.transform(np.array(y_test).reshape(-1, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9692f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Define musical note names\n",
    "NOTE_NAMES = [\"C\", \"Cs\", \"D\", \"Eb\", \"E\", \"F\", \"Fs\", \"G\", \"Gs\", \"A\", \"Bb\", \"B\"]\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "\n",
    "# Define a learning rate schedule function\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.001  # Set your initial learning rate here\n",
    "    decay = 0.95  # Set the decay rate\n",
    "    if epoch > 5:  # Adjust this condition based on when you want to start reducing the learning rate\n",
    "        return initial_learning_rate * (decay ** (epoch - 5))\n",
    "    else:\n",
    "        return initial_learning_rate\n",
    "\n",
    "# Create a learning rate scheduler callback\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Create a neural network model\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y_train_encoded)), activation='softmax')  # Output layer with softmax for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5a9b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (346, 44100)\n",
      "X_test shape: (87, 44100)\n",
      "y_train_encoded shape: (346,)\n",
      "y_test_encoded shape: (87,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of your data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train_encoded shape:\", y_train_encoded.shape)\n",
    "print(\"y_test_encoded shape:\", y_test_encoded.shape)\n",
    "\n",
    "# If there's an inconsistency, check your data split\n",
    "# Ensure that you are using the same random_state in train_test_split for reproducibility.\n",
    "# Make sure that X and y are correctly matched before the split.\n",
    "# Ensure that the test_size is reasonable and doesn't result in an extreme data split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea69df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 3s 153ms/step - loss: 10.3105 - accuracy: 0.1590 - val_loss: 5.2704 - val_accuracy: 0.1839 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 3.1377 - accuracy: 0.4451 - val_loss: 3.1942 - val_accuracy: 0.4023 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 1.2464 - accuracy: 0.7110 - val_loss: 1.8553 - val_accuracy: 0.5517 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.6162 - accuracy: 0.8121 - val_loss: 1.7980 - val_accuracy: 0.6437 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.2618 - accuracy: 0.9104 - val_loss: 1.5856 - val_accuracy: 0.6322 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.1646 - accuracy: 0.9682 - val_loss: 1.3841 - val_accuracy: 0.6897 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 136ms/step - loss: 0.0775 - accuracy: 0.9711 - val_loss: 1.1775 - val_accuracy: 0.7241 - lr: 9.5000e-04\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 0.0810 - accuracy: 0.9913 - val_loss: 1.4386 - val_accuracy: 0.7126 - lr: 9.0250e-04\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 1.2594 - val_accuracy: 0.7356 - lr: 8.5737e-04\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.0264 - accuracy: 0.9971 - val_loss: 1.1938 - val_accuracy: 0.7471 - lr: 8.1451e-04\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 1.1522 - val_accuracy: 0.7931 - lr: 7.7378e-04\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.0075 - accuracy: 0.9971 - val_loss: 1.1494 - val_accuracy: 0.7816 - lr: 7.3509e-04\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 1.1568 - val_accuracy: 0.8046 - lr: 6.9834e-04\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 1.1336 - val_accuracy: 0.7701 - lr: 6.6342e-04\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.0157 - accuracy: 0.9971 - val_loss: 1.1065 - val_accuracy: 0.7701 - lr: 6.3025e-04\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.0118 - accuracy: 0.9971 - val_loss: 1.1198 - val_accuracy: 0.7816 - lr: 5.9874e-04\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.0136 - accuracy: 0.9942 - val_loss: 1.1130 - val_accuracy: 0.7931 - lr: 5.6880e-04\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 2s 140ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 1.1290 - val_accuracy: 0.7816 - lr: 5.4036e-04\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 123ms/step - loss: 0.0280 - accuracy: 0.9942 - val_loss: 1.1898 - val_accuracy: 0.7816 - lr: 5.1334e-04\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 1.1816 - val_accuracy: 0.7931 - lr: 4.8767e-04\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 1.1688 - val_accuracy: 0.7816 - lr: 4.6329e-04\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.1715 - val_accuracy: 0.7816 - lr: 4.4013e-04\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0134 - accuracy: 0.9971 - val_loss: 1.1591 - val_accuracy: 0.7816 - lr: 4.1812e-04\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0117 - accuracy: 0.9942 - val_loss: 1.1468 - val_accuracy: 0.7701 - lr: 3.9721e-04\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.0073 - accuracy: 0.9971 - val_loss: 1.1315 - val_accuracy: 0.7701 - lr: 3.7735e-04\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0121 - accuracy: 0.9942 - val_loss: 1.1122 - val_accuracy: 0.7701 - lr: 3.5849e-04\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0107 - accuracy: 0.9942 - val_loss: 1.1328 - val_accuracy: 0.7816 - lr: 3.4056e-04\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0070 - accuracy: 0.9971 - val_loss: 1.1188 - val_accuracy: 0.7701 - lr: 3.2353e-04\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0065 - accuracy: 0.9971 - val_loss: 1.1164 - val_accuracy: 0.7701 - lr: 3.0736e-04\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 1.1226 - val_accuracy: 0.7816 - lr: 2.9199e-04\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0078 - accuracy: 0.9971 - val_loss: 1.1226 - val_accuracy: 0.7816 - lr: 2.7739e-04\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0057 - accuracy: 0.9942 - val_loss: 1.1177 - val_accuracy: 0.7701 - lr: 2.6352e-04\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.0069 - accuracy: 0.9942 - val_loss: 1.1191 - val_accuracy: 0.7816 - lr: 2.5034e-04\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0066 - accuracy: 0.9942 - val_loss: 1.1208 - val_accuracy: 0.7816 - lr: 2.3783e-04\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 2s 143ms/step - loss: 0.0055 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 2.2594e-04\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 85ms/step - loss: 0.0072 - accuracy: 0.9942 - val_loss: 1.1215 - val_accuracy: 0.7816 - lr: 2.1464e-04\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.0061 - accuracy: 0.9942 - val_loss: 1.1207 - val_accuracy: 0.7816 - lr: 2.0391e-04\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 2s 138ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.1144 - val_accuracy: 0.7816 - lr: 1.9371e-04\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 130ms/step - loss: 0.0058 - accuracy: 0.9971 - val_loss: 1.1158 - val_accuracy: 0.7816 - lr: 1.8403e-04\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.0054 - accuracy: 0.9971 - val_loss: 1.1193 - val_accuracy: 0.7816 - lr: 1.7482e-04\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.0056 - accuracy: 0.9942 - val_loss: 1.1208 - val_accuracy: 0.7816 - lr: 1.6608e-04\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.1210 - val_accuracy: 0.7816 - lr: 1.5778e-04\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.0057 - accuracy: 0.9971 - val_loss: 1.1235 - val_accuracy: 0.7816 - lr: 1.4989e-04\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0053 - accuracy: 0.9971 - val_loss: 1.1199 - val_accuracy: 0.7816 - lr: 1.4240e-04\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 134ms/step - loss: 0.0072 - accuracy: 0.9971 - val_loss: 1.1153 - val_accuracy: 0.7816 - lr: 1.3528e-04\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 139ms/step - loss: 0.0054 - accuracy: 0.9971 - val_loss: 1.1196 - val_accuracy: 0.7816 - lr: 1.2851e-04\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0053 - accuracy: 0.9942 - val_loss: 1.1208 - val_accuracy: 0.7816 - lr: 1.2209e-04\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0060 - accuracy: 0.9942 - val_loss: 1.1175 - val_accuracy: 0.7816 - lr: 1.1598e-04\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 1.1211 - val_accuracy: 0.7816 - lr: 1.1018e-04\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.0056 - accuracy: 0.9971 - val_loss: 1.1197 - val_accuracy: 0.7816 - lr: 1.0467e-04\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.1222 - val_accuracy: 0.7816 - lr: 9.9440e-05\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0066 - accuracy: 0.9942 - val_loss: 1.1167 - val_accuracy: 0.7816 - lr: 9.4468e-05\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1196 - val_accuracy: 0.7816 - lr: 8.9745e-05\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.0056 - accuracy: 0.9971 - val_loss: 1.1209 - val_accuracy: 0.7816 - lr: 8.5258e-05\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 1.1193 - val_accuracy: 0.7816 - lr: 8.0995e-05\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 1.1189 - val_accuracy: 0.7816 - lr: 7.6945e-05\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 1s 133ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1172 - val_accuracy: 0.7816 - lr: 7.3098e-05\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 1s 127ms/step - loss: 0.0055 - accuracy: 0.9942 - val_loss: 1.1193 - val_accuracy: 0.7816 - lr: 6.9443e-05\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 6.5971e-05\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 1.1169 - val_accuracy: 0.7816 - lr: 6.2672e-05\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 1s 115ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 1.1172 - val_accuracy: 0.7816 - lr: 5.9539e-05\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1167 - val_accuracy: 0.7816 - lr: 5.6562e-05\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 1.1164 - val_accuracy: 0.7816 - lr: 5.3734e-05\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1179 - val_accuracy: 0.7816 - lr: 5.1047e-05\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0052 - accuracy: 0.9971 - val_loss: 1.1172 - val_accuracy: 0.7816 - lr: 4.8495e-05\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.0049 - accuracy: 0.9942 - val_loss: 1.1182 - val_accuracy: 0.7816 - lr: 4.6070e-05\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1188 - val_accuracy: 0.7816 - lr: 4.3766e-05\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0051 - accuracy: 0.9971 - val_loss: 1.1196 - val_accuracy: 0.7816 - lr: 4.1578e-05\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1189 - val_accuracy: 0.7816 - lr: 3.9499e-05\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 1s 112ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1187 - val_accuracy: 0.7816 - lr: 3.7524e-05\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1182 - val_accuracy: 0.7816 - lr: 3.5648e-05\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1170 - val_accuracy: 0.7816 - lr: 3.3866e-05\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 1s 119ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1178 - val_accuracy: 0.7816 - lr: 3.2172e-05\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 1s 122ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1169 - val_accuracy: 0.7816 - lr: 3.0564e-05\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0050 - accuracy: 0.9971 - val_loss: 1.1168 - val_accuracy: 0.7816 - lr: 2.9035e-05\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 2.7584e-05\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0048 - accuracy: 0.9942 - val_loss: 1.1177 - val_accuracy: 0.7816 - lr: 2.6205e-05\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 1s 137ms/step - loss: 0.0050 - accuracy: 0.9942 - val_loss: 1.1182 - val_accuracy: 0.7816 - lr: 2.4894e-05\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1181 - val_accuracy: 0.7816 - lr: 2.3650e-05\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1179 - val_accuracy: 0.7816 - lr: 2.2467e-05\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 1s 129ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1178 - val_accuracy: 0.7816 - lr: 2.1344e-05\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.0049 - accuracy: 0.9942 - val_loss: 1.1181 - val_accuracy: 0.7816 - lr: 2.0277e-05\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 1s 126ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1180 - val_accuracy: 0.7816 - lr: 1.9263e-05\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 1s 116ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1180 - val_accuracy: 0.7816 - lr: 1.8300e-05\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 1s 117ms/step - loss: 0.0048 - accuracy: 0.9942 - val_loss: 1.1175 - val_accuracy: 0.7816 - lr: 1.7385e-05\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 1s 131ms/step - loss: 0.0048 - accuracy: 0.9942 - val_loss: 1.1177 - val_accuracy: 0.7816 - lr: 1.6515e-05\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.0049 - accuracy: 0.9942 - val_loss: 1.1179 - val_accuracy: 0.7816 - lr: 1.5690e-05\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 1s 124ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 1.4905e-05\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 1s 139ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1172 - val_accuracy: 0.7816 - lr: 1.4160e-05\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 1s 120ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 1.3452e-05\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 1s 118ms/step - loss: 0.0050 - accuracy: 0.9942 - val_loss: 1.1184 - val_accuracy: 0.7816 - lr: 1.2779e-05\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1181 - val_accuracy: 0.7816 - lr: 1.2140e-05\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 1.1533e-05\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 1s 114ms/step - loss: 0.0049 - accuracy: 0.9971 - val_loss: 1.1171 - val_accuracy: 0.7816 - lr: 1.0957e-05\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 1s 135ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 1.0409e-05\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 1s 121ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1177 - val_accuracy: 0.7816 - lr: 9.8884e-06\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 1s 128ms/step - loss: 0.0049 - accuracy: 0.9942 - val_loss: 1.1182 - val_accuracy: 0.7816 - lr: 9.3939e-06\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 1s 138ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1183 - val_accuracy: 0.7816 - lr: 8.9242e-06\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1176 - val_accuracy: 0.7816 - lr: 8.4780e-06\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.0048 - accuracy: 0.9971 - val_loss: 1.1175 - val_accuracy: 0.7816 - lr: 8.0541e-06\n"
     ]
    }
   ],
   "source": [
    "# Train your model using X_train_augmented\n",
    "early_stopping = EarlyS3topping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train_encoded, epochs=100, batch_size=32,\n",
    "                    validation_data=(X_test, y_test_encoded),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e1ce19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1175 - accuracy: 0.7816\n",
      "Test Loss: 1.1175, Test Accuracy: 0.7816\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using encoded labels\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a85fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea151d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib scipy plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4ff9e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fft(p, xf, fs, notes):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(\"Frequency Spectrum\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.plot(xf, p)\n",
    "\n",
    "    for note in notes:\n",
    "        plt.annotate(note[1], (note[0] + 10, note[2]), fontsize=12, ha='center', va='bottom')\n",
    "\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def extract_sample(audio, frame_number, frame_offset):\n",
    "    end = frame_number * frame_offset\n",
    "    begin = int(end - FFT_WINDOW_SIZE)\n",
    "\n",
    "    if end == 0:\n",
    "        return np.zeros((np.abs(begin)), dtype=float)\n",
    "    elif begin < 0:\n",
    "        return np.concatenate([np.zeros((np.abs(begin)), dtype=float), audio[0:end]])\n",
    "    else:\n",
    "        return audio[begin:end]\n",
    "\n",
    "def find_top_notes(fft, num, xf):\n",
    "    if np.max(fft.real) < 0.001:\n",
    "        return []\n",
    "\n",
    "    lst = [x for x in enumerate(fft.real)]\n",
    "    lst = sorted(lst, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    idx = 0\n",
    "    found = []\n",
    "    found_note = set()\n",
    "    while (idx < len(lst)) and (len(found) < num):\n",
    "        f = xf[lst[idx][0]]\n",
    "        y = lst[idx][1]\n",
    "        n = freq_to_number(f)\n",
    "        n0 = int(round(n))\n",
    "        name = note_name(n0)\n",
    "\n",
    "        if name not in found_note:\n",
    "            found_note.add(name)\n",
    "            s = [f, note_name(n0), y]\n",
    "            found.append(s)\n",
    "        idx += 1\n",
    "\n",
    "    return found\n",
    "\n",
    "def freq_to_number(f): return 69 + 12 * np.log2(f / 440.0)\n",
    "def note_name(n): return NOTE_NAMES[n % 12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c072d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_fft(magnitudes, sample_rate, notes, xlim=None):\n",
    "#     fft_values = np.fft.fftfreq(len(magnitudes), 1.0 / sample_rate)\n",
    "# #\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.title(\"Frequency Spectrum\")\n",
    "#     plt.xlabel(\"Frequency (Hz)\")\n",
    "#     plt.ylabel(\"Magnitude\")\n",
    "#     plt.plot(fft_values, magnitudes)\n",
    "    \n",
    "#     if xlim:\n",
    "#         plt.xlim(xlim)\n",
    "    \n",
    "#     for note in notes:\n",
    "#         plt.annotate(note[1], (note[0] + 10, note[2]), fontsize=12, ha='center', va='bottom')\n",
    "    \n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "# # Example: Replace this with your actual audio_samples and sample_rate\n",
    "# # Generate random audio data for demonstration purposes\n",
    "# sample_rate = 44100\n",
    "# duration = 5  # 5 seconds of audio\n",
    "# num_samples = int(sample_rate * duration)\n",
    "# audio_samples = np.random.randn(num_samples)\n",
    "\n",
    "# # Extract features and notes (replace with your actual audio and notes)\n",
    "# features = extract_features([audio_samples])\n",
    "# num_notes = 5  # Adjust the number of top notes you want to display\n",
    "\n",
    "# for feature in features:\n",
    "#     notes = find_top_notes(feature, num_notes, fft_values)  # Replace with your notes\n",
    "#     plot_fft(feature, sample_rate, notes, xlim=(0, 1000))  # Adjust frequency range if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d186a315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trial1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: trial1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"trial1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2302c10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "Predicted Note: B\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define musical note names\n",
    "NOTE_NAMES = [\"C\", \"Cs\", \"D\", \"Eb\", \"E\", \"F\", \"Fs\", \"G\", \"Gs\", \"A\", \"Bb\", \"B\"]\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('trial1')  # Replace 'your_model_path' with the actual path to your trained model\n",
    "\n",
    "def extract_features(audio):\n",
    "    # Applying FFT\n",
    "    fft_result = np.fft.fft(audio)\n",
    "    magnitudes = np.abs(fft_result)\n",
    "    return magnitudes\n",
    "\n",
    "def predict_note(audio_file_path, model):\n",
    "    # Load and process the audio file\n",
    "    audio, _ = librosa.load(audio_file_path, sr=None)\n",
    "    features = extract_features(audio)\n",
    "    \n",
    "    # Make sure the features have the same shape as the model's input shape\n",
    "    if len(features) < X_train.shape[1]:\n",
    "        features = np.pad(features, (0, X_train.shape[1] - len(features)))\n",
    "    elif len(features) > X_train.shape[1]:\n",
    "        features = features[:X_train.shape[1]]\n",
    "    \n",
    "    features = np.array([features])  # Reshape for model input\n",
    "    \n",
    "    # Make a prediction using the trained model\n",
    "    prediction = model.predict(features)\n",
    "    \n",
    "    # Convert prediction to musical note\n",
    "    predicted_note_index = np.argmax(prediction)\n",
    "    predicted_note = NOTE_NAMES[predicted_note_index]\n",
    "    \n",
    "    return predicted_note\n",
    "\n",
    "# Example usage:\n",
    "# audio_file_path = '88-piano_new/C_6.wav'  # Replace 'your_audio_file_path.wav' with the path to the user's input audio file\n",
    "audio_file_path = 'piano_triads/Cs_maj_5_0.wav' \n",
    "predicted_note = predict_note(audio_file_path, model)\n",
    "print(f\"Predicted Note: {predicted_note}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa826e9",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61add361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
